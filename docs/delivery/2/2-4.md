# Task 2-4: Build Duplicate Detection Service

[Back to task list](./tasks.md)

## Description

Create a service to detect duplicate transactions before importing them to the database. This prevents the same transactions from being imported multiple times from the same or different CSV files.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-10-19 20:18:00 | Created | N/A | Proposed | Task created | Saeed |
| 2025-10-19 20:18:00 | Approved | Proposed | Agreed | Task approved for implementation | Saeed |
| 2025-10-19 20:18:00 | Started | Agreed | InProgress | Beginning implementation | Saeed |
| 2025-10-19 20:25:00 | Completed | InProgress | Review | Duplicate detector service implemented, all 14 tests passing | Saeed |
| 2025-10-19 20:26:00 | Approved | Review | Done | Duplicate detection working with configurable confidence thresholds | Saeed |

## Requirements

1. Detect duplicate transactions based on multiple criteria
2. Match by: account_id + date + amount + description (exact or similar)
3. Handle partial matches (e.g., description variations)
4. Return list of potential duplicates with confidence scores
5. Allow configurable matching thresholds
6. Support bulk duplicate checking (list of transactions)
7. Provide clear duplicate indicators in import preview

## Implementation Plan

### 1. Create Duplicate Detection Service (`src/services/duplicate_detector.py`)

**Matching Strategy:**
- **Exact Match**: Same account, date, amount, and description (100% confidence)
- **High Confidence Match**: Same account, date, amount, similar description (80%+ confidence)
- **Possible Match**: Same account, similar date (±2 days), similar amount (±5%), similar description (60%+ confidence)

**Similarity Algorithms:**
- Use Levenshtein distance for description matching
- Normalize descriptions (lowercase, trim, remove extra spaces)
- Ignore common words (e.g., "transaction", "payment")

**Return Format:**
```python
{
    'transaction': {...},  # The transaction being checked
    'is_duplicate': True/False,
    'confidence': 0.95,  # 0.0 to 1.0
    'matches': [
        {
            'existing_transaction': {...},
            'confidence': 0.95,
            'match_type': 'exact' | 'high' | 'possible'
        }
    ]
}
```

### 2. Integration with Import Workflow

- Check for duplicates before storing transactions
- Add duplicate indicators to import preview UI
- Allow user to decide whether to import duplicates
- Optionally skip duplicates automatically

### 3. Database Queries

**Efficient Queries:**
- Index on (account_id, date, amount) for fast lookups
- Query transactions within date range (±2 days)
- Filter by account_id and amount range

### 4. Configuration

**Configurable Thresholds:**
- `EXACT_MATCH_THRESHOLD = 1.0`
- `HIGH_CONFIDENCE_THRESHOLD = 0.8`
- `POSSIBLE_MATCH_THRESHOLD = 0.6`
- `DATE_TOLERANCE_DAYS = 2`
- `AMOUNT_TOLERANCE_PERCENT = 5`

## Test Plan

**Success Criteria:**
- Detect exact duplicate transactions (100%)
- Detect high-confidence duplicates with similar descriptions (80%+)
- Identify possible duplicates with minor variations (60%+)
- No false positives for clearly different transactions
- Performance: Check 100 transactions against 10,000 existing in <1 second

**Unit Tests:**
- `test_exact_duplicate_detection()`
- `test_high_confidence_duplicate()`
- `test_possible_duplicate_similar_description()`
- `test_no_duplicate_different_amount()`
- `test_no_duplicate_different_date()`
- `test_no_duplicate_different_account()`
- `test_description_similarity_calculation()`
- `test_bulk_duplicate_check()`
- `test_configurable_thresholds()`

**Integration Tests:**
- `test_duplicate_detection_in_import_workflow()`
- `test_skip_duplicates_option()`
- `test_duplicate_indicators_in_preview()`

## Verification

- [x] Duplicate detection service created
- [x] Exact match detection working
- [x] High confidence match detection working
- [x] Possible match detection working
- [x] Description similarity algorithm implemented
- [x] Configurable thresholds working
- [ ] Integration with import workflow (future enhancement)
- [x] Tests passing (14/14 tests)

## Files Modified

**Created:**
- `src/services/duplicate_detector.py`
- `tests/unit/test_duplicate_detector.py`

**Modified:**
- `src/routes/import_routes.py` (integrate duplicate detection)
- `src/templates/import.html` (show duplicate indicators)
- `tests/integration/test_import.py` (add duplicate detection tests)

## Notes

- Use Python's `difflib.SequenceMatcher` for string similarity
- Consider using fuzzy matching libraries like `fuzzywuzzy` if needed
- Start with simple exact matching, then add fuzzy matching
- Performance is important - optimize database queries
- User should have final say on whether to import duplicates


